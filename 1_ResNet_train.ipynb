{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "import math\n",
    "from torch.functional import F\n",
    "import pennylane as qml\n",
    "\n",
    "# Hyperparameters\n",
    "apply_augmentation = True\n",
    "batch_size = 8\n",
    "load_saved_model = False\n",
    "training_epoch = 150\n",
    "learning_rate = 0.0008\n",
    "momentum = 0.9\n",
    "weight_decay = 0.000005\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_size = 1\n",
    "\n",
    "root_folder = \"AIDER\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 256x256\n",
    "    transforms.ToTensor(),          # Convert images to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "dataset = datasets.ImageFolder(root=root_folder, transform=transform)\n",
    "\n",
    "# Split train and test and put in dataloader\n",
    "full_dataset_size = len(dataset)\n",
    "subset_size = int(fraction_size * full_dataset_size)\n",
    "subset_indices = torch.randperm(full_dataset_size)[:subset_size].tolist()\n",
    "subset = Subset(dataset, subset_indices)\n",
    "\n",
    "train_size = int(0.6 * len(subset))\n",
    "test_size = len(subset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(subset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  23158 , Test size:  2574\n"
     ]
    }
   ],
   "source": [
    "if apply_augmentation:\n",
    "    # Geometry augmentation\n",
    "    transform1 = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(80),\n",
    "        transforms.Resize((224, 224)),  # Resize images to 256x256\n",
    "        transforms.ToTensor(),          # Convert images to Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "    ])\n",
    "    augmented1 = datasets.ImageFolder(root=root_folder, transform=transform1)\n",
    "    \n",
    "    # Color augmentation\n",
    "    transform2 = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        transforms.Resize((224, 224)),  # Resize images to 256x256\n",
    "        transforms.ToTensor(),          # Convert images to Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "    ])\n",
    "    augmented2 = datasets.ImageFolder(root=root_folder, transform=transform2)\n",
    "    \n",
    "    # Noise augmentation\n",
    "    transform3 = transforms.Compose([\n",
    "        transforms.GaussianBlur(3),\n",
    "        transforms.Resize((224, 224)),  # Resize images to 256x256\n",
    "        transforms.ToTensor(),          # Convert images to Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "    ])\n",
    "    augmented3 = datasets.ImageFolder(root=root_folder, transform=transform3)\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset, augmented1, augmented2, augmented3])\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Train size: \", len(train_dataset), \", Test size: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUANTUM BLOCK\n",
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "n_layers = 4\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "dev_quantum = torch.device(device)\n",
    "\n",
    "# Define the quantum node\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "expanded_circuit = qml.transforms.broadcast_expand(qnode)\n",
    "class QNet(torch.nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.qlayer = qml.qnn.TorchLayer(expanded_circuit, weight_shapes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.qlayer(x.to('cpu')).to(dev_quantum)  # Ensure compatibility with quantum layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x32 and 16x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     84\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader_train))\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 66\u001b[0m, in \u001b[0;36mQCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m fusion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1, x2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m fusion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(fusion, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfusion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x32 and 16x5)"
     ]
    }
   ],
   "source": [
    "# from architectures.vit import ViT\n",
    "from vit_pytorch import ViT\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "#self.features = models.resnet34(pretrained =True)\n",
    "\n",
    "class QCNN(nn.Module): \n",
    "    def __init__(self) -> None:\n",
    "        super(QCNN, self).__init__()\n",
    "        # self.features = models.resnet34(pretrained =True)\n",
    "        self.resnet = models.resnet50(pretrained =True)\n",
    "        self.seq_resnet = nn.Sequential(\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 16),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(0.1),\n",
    "            # nn.Linear(16, 5)\n",
    "        )\n",
    "        self.seq_to_qnet = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, 4)\n",
    "        )\n",
    "        self.vit = ViT(\n",
    "            image_size = 256,\n",
    "            patch_size = 32,\n",
    "            num_classes = 2,\n",
    "            dim = 1024,\n",
    "            depth = 10,\n",
    "            heads = 16,\n",
    "            mlp_dim = 2048,\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1\n",
    "        )\n",
    "        self.qnet = QNet(4) # From 2 to 16\n",
    "        # Do interpolation to 16 features\n",
    "        self.seq_after_qnet = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4, 16)\n",
    "        )\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, 5)\n",
    "        ) # From 16 to 5\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x) \n",
    "        x1 = self.seq_resnet(x) # 16 features\n",
    "        x2 = self.seq_to_qnet(x1)\n",
    "        x2 = self.qnet(x2) \n",
    "        x2 = self.seq_after_qnet(x2) #16 features\n",
    "        fusion = x1 + x2\n",
    "        output = self.seq(fusion)\n",
    "        return output\n",
    "\n",
    "\n",
    "# model = ViT(\n",
    "#     image_size = 256,\n",
    "#     patch_size = 16,\n",
    "#     num_classes = 5,\n",
    "#     dim = 1024,\n",
    "#     depth = 10,\n",
    "#     heads = 16,\n",
    "#     mlp_dim = 2048,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1\n",
    "# ).to(device)\n",
    "\n",
    "model = QCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "example = next(iter(dataloader_train))\n",
    "print(model(example[0].to(device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "class Engine(object):\n",
    "    def __init__(self, model, optimizer, device, ema=None):\n",
    "        # Initialize the Engine with the model, optimizer, and the device it's running on.\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        # Current epoch of training.\n",
    "        self.cur_epoch = 0\n",
    "        # Number of iterations the training has run.\n",
    "        self.cur_iter = 0\n",
    "        # The best validation epoch, used to track the epoch with the best validation performance.\n",
    "        self.bestval_epoch = 0\n",
    "        # Lists to track the training and validation losses.\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        # Criterion for calculating loss. Here, it's Mean Squared Error Loss for regression tasks.\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    \"\"\" Block to begin training \"\"\"\n",
    "    def train(self, dataloader_train):\n",
    "        loss_epoch = 0.\n",
    "        num_batches = 0\n",
    "        # Set the model to training mode.\n",
    "        self.model.train()\n",
    "        \n",
    "        # Train loop\n",
    "        # tqdm is used to display the training progress for each epoch.\n",
    "        pbar = tqdm(dataloader_train, desc='Train Epoch {}'.format(self.cur_epoch))\n",
    "        for data in pbar:\n",
    "            # efficiently zero gradients\n",
    "            # Zero the gradients before running the backward pass.\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            images = data[0].to(self.device, dtype=torch.float32)   # Image that will be fed into network\n",
    "            gt_label = data[1].to(self.device, dtype=torch.long)\n",
    "\n",
    "            # Pass the images through the model to get predictions.\n",
    "            pred_label = self.model(images)\n",
    "            \n",
    "            # Calculate the loss, backpropagation, and optimization\n",
    "            loss = self.criterion(pred_label, gt_label)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Perform a single optimization step (parameter update).\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Aggregate the loss for the epoch\n",
    "            loss_epoch += float(loss.item())\n",
    "            num_batches += 1\n",
    "            pbar.set_description(\"Loss: {:.4f}\".format(loss.item()))\n",
    "            \n",
    "        pbar.close()\n",
    "        avg_loss = loss_epoch / num_batches\n",
    "        self.train_loss.append(avg_loss)\n",
    "        \n",
    "        self.cur_epoch += 1\n",
    "        pbar.set_description(\"Epoch: {}, Average Loss: {:.4f}\".format(self.cur_epoch, avg_loss))\n",
    "\n",
    "    def test(self, dataloader_test):\n",
    "        # self.model.eval()  # Set the model to evaluation mode\n",
    "        loss_epoch = 0.\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Prepare to collect predictions and ground truth\n",
    "        predictions = []\n",
    "        ground_truths = []\n",
    "        \n",
    "        with torch.no_grad():  # No need to calculate gradients\n",
    "            pbar = tqdm(dataloader_test, desc='Test Epoch {}'.format(self.cur_epoch))\n",
    "            for data in pbar:\n",
    "                images = data[0].to(self.device, dtype=torch.float32)   # Image that will be fed into network\n",
    "                gt_label = data[1].to(self.device, dtype=torch.long)  # GT_label\n",
    "\n",
    "                # Pass the images through the model to get predictions.\n",
    "                pred_label = self.model(images)\n",
    "\n",
    "                # Calculate the loss, backpropagation, and optimization\n",
    "                loss = self.criterion(pred_label, gt_label)\n",
    "                loss_epoch += float(loss.item())\n",
    "                num_batches += 1\n",
    "                \n",
    "                # We want to put this back on the CPU to calculate the metrics\n",
    "                predictions.extend(pred_label.argmax(dim=1).cpu().numpy().flatten())\n",
    "                ground_truths.extend(gt_label.cpu().numpy().flatten())\n",
    "                pbar.set_description(\"Test Loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "        avg_loss = loss_epoch / num_batches\n",
    "        self.val_loss.append(avg_loss)\n",
    "\n",
    "        # Print the accuracy here\n",
    "        accuracy = accuracy_score(ground_truths, predictions)\n",
    "        \n",
    "        # Generate the confusion matrix\n",
    "        cm = confusion_matrix(ground_truths, predictions)\n",
    "        \n",
    "        # Plot the heatmap using Seaborn\n",
    "        plt.figure(figsize=(4,4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix for Epoch {self.cur_epoch}')\n",
    "        plt.ylabel('Actual Labels')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(f\"Test Epoch: {self.cur_epoch}, Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Total trainable parameters:  113413235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0:   0%|          | 0/724 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [5], target: [32])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======Total trainable parameters: \u001b[39m\u001b[38;5;124m'\u001b[39m, params)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainer\u001b[38;5;241m.\u001b[39mcur_epoch, training_epoch):\n\u001b[0;32m---> 13\u001b[0m \t\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \t\u001b[38;5;66;03m# Test the model every 20 epochs and save it to logs folder\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m (epoch) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mEngine.train\u001b[0;34m(self, dataloader_train)\u001b[0m\n\u001b[1;32m     43\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate the loss, backpropagation, and optimization\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Perform a single optimization step (parameter update).\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/qcnn/lib/python3.9/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [5], target: [32])"
     ]
    }
   ],
   "source": [
    "trainer = Engine(model, optimizer, device, ema=None)\n",
    "\n",
    "# Load the saved model if load_saved_model is set to True\n",
    "if load_saved_model:\n",
    "\tmodel.load_state_dict(torch.load('logs/final_model.pth'))\n",
    " \n",
    "# Count the total number of trainable parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print ('======Total trainable parameters: ', params)\n",
    "\n",
    "for epoch in range(trainer.cur_epoch, training_epoch):\n",
    "\ttrainer.train(dataloader_train)\n",
    "\n",
    "\t# Test the model every 20 epochs and save it to logs folder\n",
    "\tif (epoch) % 10 == 0:\n",
    "\t\ttrainer.test(dataloader_test)\n",
    "\t\ttorch.save(model.state_dict(), os.path.join('logs', 'final_model.pth'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
